{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8394439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8b499",
   "metadata": {},
   "source": [
    "##### Fonction qui sauvegarde des dataframes dans un joli format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189a810b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_fwf(df, fname, cols=None):\n",
    "    \"\"\"Custom method 'to_fwf' for Pandas\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        The path to the new file in which the hidden parameters will be written\n",
    "    cols : list or array of strings, optional\n",
    "        A list or an array containing the name of the columns (as strings) to\n",
    "        be written in the file (if None all columns will be written).\n",
    "    \"\"\"\n",
    "\n",
    "    if cols is None:\n",
    "        cols = df.columns\n",
    "\n",
    "    header = list(cols)\n",
    "    header[0] = '# ' + header[0]\n",
    "    content = tabulate.tabulate(df[cols].values.tolist(), header,\n",
    "                                tablefmt='plain', stralign='right',\n",
    "                                colalign=('left',))\n",
    "    open(fname, 'w').write(content)\n",
    "\n",
    "\n",
    "# Adds the custom method to Pandas.\n",
    "pd.DataFrame.to_fwf = to_fwf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92295f2f",
   "metadata": {},
   "source": [
    "##### Charge les propriétés déjà calculées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70f775e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "graphPropFilename = 'graph_data/graph_properties.txt'\n",
    "header = open(graphPropFilename, 'r').readline().replace('#', ' ').split()\n",
    "graphPropDF = pd.read_table(graphPropFilename, names=header, comment=\"#\",\n",
    "                            delimiter=r\"\\s+\")\n",
    "graphPropList = graphPropDF.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ffb2e8",
   "metadata": {},
   "source": [
    "##### Code copié-collé du fichier `get_real_networks.py` (update 2023-03-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885482b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy.io\n",
    "import warnings\n",
    "from split_weight_nws import unpack\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "def get_connectome_weight_matrix(graph_name):\n",
    "    \"\"\"\n",
    "    Return the weight matrix for a given graph.\n",
    "    graph_name (str): \"mouse_meso\", \"zebrafish_meso\", \"celegans\",\n",
    "                      \"celegans_signed\", \"drosophila\", \"ciona\",\n",
    "                      \"platynereis_dumerilii_neuronal\"\n",
    "    \"\"\"\n",
    "    path_str = \"graph_data/connectomes/\"\n",
    "\n",
    "    if graph_name == \"celegans\":\n",
    "        # Data obtained from Mohamed Bahdine, extracted as described in the\n",
    "        # supplementary material of the article : Network control principles\n",
    "        # predict neuron function in the C. elegans connectome - Yan et al.\n",
    "        # The data come from Wormatlas.\n",
    "        A = np.array(1 * np.load(path_str + \"C_Elegans.npy\"))\n",
    "        # N = 279\n",
    "        # rank_celegans = 273\n",
    "\n",
    "    elif graph_name == \"celegans_signed\":\n",
    "        # Data: https://elegansign.linkgroup.hu/#!NT+R%20method%20prediction\n",
    "        # Paper: https://doi.org/10.1371/journal.pcbi.1007974\n",
    "        df = pd.read_excel(\n",
    "            path_str + 'celegans_weighted_directed_signed.xls',\n",
    "            usecols=\"A,D,E,P\")\n",
    "        df = df.replace(to_replace=['+', '-', 'no pred', 'complex'],\n",
    "                        value=[1, -1, 0, 0])\n",
    "        df_dale = df[[\"Source\"]]\n",
    "        df_dale[\"Strength x Sign\"] = df[\"Edge Weight\"] * df[\"Sign\"]\n",
    "        df_dale = df_dale.groupby(['Source']).sum()\n",
    "        # We complete the missing data using Dale's principle, i.e., if most\n",
    "        # of the synapses of a neuron are excitatory (inhibitory), then we\n",
    "        #  consider that the unknown ones are excitatory (inhibitory). When no\n",
    "        # information allows to apply Dale's principle, we consider the neuron\n",
    "        # as an excitator given the fact that there are more excitators than\n",
    "        # inhibitors in connectomes.\n",
    "        for i, neuron in enumerate(df[\"Source\"]):\n",
    "            if df[\"Sign\"].values[i] == 0 \\\n",
    "                    and df_dale.loc[neuron].values[0] >= 0:\n",
    "                df.loc[i, ['Sign']] = 1\n",
    "            elif df[\"Sign\"].values[i] == 0 \\\n",
    "                    and df_dale.loc[neuron].values[0] < 0:\n",
    "                df.loc[i, ['Sign']] = -1\n",
    "        df[\"Weight x Sign\"] = df[\"Edge Weight\"] * df[\"Sign\"]\n",
    "        # with pd.option_context('display.max_rows', None,\n",
    "        #                        'display.max_columns', None):\n",
    "        #     print(df)\n",
    "        # print(df[\"Weight x Sign\"].sum())\n",
    "        G_celegans = nx.from_pandas_edgelist(df,\n",
    "                                             source='Source',\n",
    "                                             target='Target',\n",
    "                                             edge_attr='Weight x Sign',\n",
    "                                             create_using=nx.DiGraph())\n",
    "        A = nx.to_numpy_array(G_celegans, weight='Weight x Sign')\n",
    "        # N = 297\n",
    "\n",
    "    elif graph_name == \"drosophila\":\n",
    "        df = pd.read_csv(\n",
    "            path_str + 'drosophila_exported-traced-adjacencies-v1.1/'\n",
    "                       'traced-total-connections.csv')\n",
    "        Graphtype = nx.DiGraph()\n",
    "        G_drosophila = nx.from_pandas_edgelist(df,\n",
    "                                               source='bodyId_pre',\n",
    "                                               target='bodyId_post',\n",
    "                                               edge_attr='weight',\n",
    "                                               create_using=Graphtype)\n",
    "        A = nx.to_numpy_array(G_drosophila, weight='weight')\n",
    "        # N = 21733\n",
    "        # srank = 11.5811\n",
    "\n",
    "    elif graph_name == \"cintestinalis\":\n",
    "        A_from_xlsx = pd.read_excel(path_str +\n",
    "                                    'ciona_intestinalis_lavaire_elife-16962'\n",
    "                                    '-fig16-data1-v1_modified.xlsx').values\n",
    "        A_ciona_nan = np.array(A_from_xlsx[0:, 1:])\n",
    "        A_ciona = np.array(A_ciona_nan, dtype=float)\n",
    "        where_are_NaNs = np.isnan(A_ciona)\n",
    "        A_ciona[where_are_NaNs] = 0\n",
    "        A = A_ciona\n",
    "        # A = (A_ciona > 0).astype(float)\n",
    "        # N = 213\n",
    "        # rank = 203\n",
    "\n",
    "    elif graph_name == \"mouse_meso\":\n",
    "        # Oh, S., Harris, J., Ng, L. et al.\n",
    "        # A mesoscale connectome of the mouse brain.\n",
    "        # Nature 508, 207–214 (2014) doi:10.1038/nature13186\n",
    "        # To binary matrix  (with \"> 0\")\n",
    "        # A = (np.loadtxt(path_str + \"ABA_weight_mouse.txt\") > 0).astype(float)\n",
    "        A = (np.loadtxt(path_str + \"ABA_weight_mouse.txt\")).astype(float)\n",
    "        # N = 213\n",
    "        # rank = 185\n",
    "\n",
    "    elif graph_name == \"mouse_voxel\":\n",
    "        # Coletta et al., \"Network structure of the mouse brain\n",
    "        #  connectome with voxel resolution\"\n",
    "\n",
    "        dictionary = scipy.io.loadmat(path_str + 'full_connectome_no_thr.mat')\n",
    "        A = dictionary['full_connectome_no_thr']\n",
    "\n",
    "    elif graph_name == \"zebrafish_meso\":\n",
    "        # Kunst et al.\n",
    "        # \"A Cellular-Resolution Atlas of the Larval Zebrafish Brain\",\n",
    "        # (2019) with the treatment of Antoine Légaré\n",
    "        # We do not have exactly the same regions than the ones in the paper\n",
    "        # where the matrix is 36 by 36. Here, we have 71 regions that are\n",
    "        # mutually exclusive and collectively exhaustive (these are the terms\n",
    "        # of the corresponding author of the above paper), in the sense that\n",
    "        # it covers the whole volume without overlap\n",
    "\n",
    "        df = pd.read_csv(path_str +\n",
    "                         'Connectivity_matrix_zebra_fish_mesoscopic.csv')\n",
    "        dictio = {'X': 0}  # We put zeros temporarily on the diagonal\n",
    "        df = df.replace(dictio)\n",
    "\n",
    "        volumes = np.array(\n",
    "            1 * np.load(path_str + \"volumes_zebrafish_meso.npy\"))\n",
    "        relativeVolumes = volumes / sum(volumes)\n",
    "        adjacency = df.to_numpy()[:, 1:-1].astype(float)\n",
    "        # \"\"\" To get an undirected graph \"\"\"\n",
    "        # for i in range(adjacency.shape[0]):\n",
    "        #     for j in range(i+1, adjacency.shape[0]):\n",
    "        #         adjacency[i, j] = (adjacency[i, j] + adjacency[j, i]) /\n",
    "        #  (relativeVolumes[i] + relativeVolumes[j])\n",
    "        #         adjacency[j, i] = adjacency[i, j]\n",
    "        \"\"\" To get a directed graph \"\"\"\n",
    "        for i in range(adjacency.shape[0]):\n",
    "            for j in range(adjacency.shape[0]):\n",
    "                adjacency[i, j] = adjacency[i, j] / (\n",
    "                        relativeVolumes[i] + relativeVolumes[j])\n",
    "        adjacency = adjacency / np.amax(adjacency)\n",
    "        adjacency = np.log(adjacency + 0.00001)\n",
    "        adjacency -= np.amin(adjacency)\n",
    "        adjacency = adjacency / np.amax(adjacency)\n",
    "        # We add a diagonal because there are interactions within modules\n",
    "        A = adjacency + np.eye(len(adjacency[0]))\n",
    "        # N = 71\n",
    "        # rank_zebrafish_meso = 71\n",
    "\n",
    "    elif graph_name == \"pdumerilii_neuronal\":\n",
    "        G_platynereis = nx.read_graphml(path_str + \"pdumerilii_neuronal.xml\")\n",
    "        A = nx.to_numpy_array(G_platynereis)\n",
    "\n",
    "    elif graph_name == \"pdumerilii_desmosomal\":\n",
    "        G_platynereis = \\\n",
    "            nx.read_graphml(path_str + \"pdumerilii_desmosomal.xml\",\n",
    "                            force_multigraph=True)\n",
    "        A = nx.to_numpy_array(G_platynereis,\n",
    "                              nodelist=sorted(G_platynereis.nodes()),\n",
    "                              multigraph_weight=sum)\n",
    "        \"\"\"\n",
    "         Note: There are repeated edges in the dataset.\n",
    "         The number of edges, confirmed with G. Jékely, is 5455 and not 6961.\n",
    "        \"\"\"\n",
    "        # print(np.all(A.T == A), np.sum(np.triu((A > 0).astype(float), 1)),\n",
    "        #       np.sum(np.triu(A)), np.sum(np.diag((A > 0).astype(float))))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"This graph_str connectome is not an option. \"\n",
    "                         \"See the documentation of \"\n",
    "                         \"get_connectome_weight_matrix\")\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def get_microbiome_weight_matrix(graph_str):\n",
    "\n",
    "    path_str = f\"graph_data/microbiomes/{graph_str}/\"\n",
    "\n",
    "    if graph_str == \"gut\":\n",
    "        # See p.27-28 of the supplementary information (SI) of\n",
    "        # Reviving a failed network through microscopic interventions\n",
    "        # and\n",
    "        # R. Lim, J.J.T. Cabatbat, T.L.P. Martin, H. Kim, S. Kim, J. Sung,\n",
    "        # C.-M. Ghim and P.-J. Kim. Large-scale metabolic interaction network\n",
    "        # of the mouse and human gut microbiota. Scientific Data, 7, 204, 2020.\n",
    "        dictionary = scipy.io.loadmat(path_str+'MicrobiomeNetworks.mat',\n",
    "                                      variable_names=['complementarity',\n",
    "                                                      'competition'])\n",
    "        P = dictionary['complementarity']\n",
    "        Q = dictionary['competition']\n",
    "\n",
    "        # These are the parameters mentionned in p.28 of the SI\n",
    "        omegaP = 30\n",
    "        omegaQ = 1\n",
    "\n",
    "        A = omegaP*P - omegaQ*Q\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"This graph_str microbiome is not an option. See the\"\n",
    "                         \" documentation of get_microbiome_weight_matrix\")\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def get_foodweb_weight_matrix(graph_str):\n",
    "\n",
    "    path_str = f\"graph_data/foodwebs/{graph_str}/\"\n",
    "\n",
    "    if graph_str == \"little_rock\":\n",
    "        # Taken from Netzschleuder : https://networks.skewed.de/\n",
    "        G = nx.read_edgelist(path_str + \"edges.csv\", delimiter=',',\n",
    "                             create_using=nx.DiGraph)\n",
    "        A = nx.to_numpy_array(G).T\n",
    "        # A_{ij} = 1, if edge j -> i (other convention in the data)\n",
    "\n",
    "    elif graph_str == \"caribbean\":\n",
    "        # Taken from Web of life : https://www.web-of-life.es/\n",
    "        A = np.genfromtxt(path_str + 'foodweb_caribbean_matrix.csv',\n",
    "                          delimiter=\",\")\n",
    "        A[np.isnan(A)] = 0\n",
    "\n",
    "        # Note: Canibalism has been found in 11 species or groups.\n",
    "        # Crabs, Shrimps, Polychaetes, Gastropods, Squids, Octopuses,\n",
    "        # Asteroids, Echinoids, Mycteroperca venenosa,\n",
    "        # Scomberomorus cavalla, Tylosurus acus\n",
    "        # We should add self-loops, because they are not included right now\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"This graph_str foodweb is not an option. \"       \n",
    "                         \"See the documentation of get_foodweb_weight_matrix\")\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def get_epidemiological_weight_matrix(graph_str):\n",
    "    path_str = f\"graph_data/epidemiological/{graph_str}/\"\n",
    "\n",
    "    if graph_str == \"high_school_proximity\":\n",
    "        # Taken from Netzschleuder : https://networks.skewed.de/\n",
    "        G = nx.read_edgelist(path_str + \"edges_no_time.csv\", delimiter=',',\n",
    "                             create_using=nx.Graph)\n",
    "        A = nx.to_numpy_array(G)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"This graph_str epidemiological is not an option. \"       \n",
    "                         \"See the documentation of\"\n",
    "                         \"get_epidemiological_weight_matrix\")\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def get_learned_weight_matrix(graph_str):\n",
    "    path_str = f\"graph_data/learned/\"\n",
    "\n",
    "    if graph_str == \"zebrafish_rnn\":        # From Hadjiabadi et al. (2021)\n",
    "        # https://data.mendeley.com/datasets/dghdz45rfd/2\n",
    "        W = np.load(path_str + f\"{graph_str}/\"\n",
    "                    + \"zebrafish1-presz-model.npz\")[\"J\"]\n",
    "\n",
    "    elif graph_str == \"mouse_rnn\":\n",
    "        # From Hadjiabadi et al. (2021)\n",
    "        # https://data.mendeley.com/datasets/dghdz45rfd/2\n",
    "        W = np.load(path_str + f\"{graph_str}/\" + \"mouse-tle1-model.npz\")[\"J\"]\n",
    "\n",
    "    elif graph_str == \"mouse_control_rnn\":\n",
    "        # From Hadjiabadi et al. (2021)\n",
    "        # https://data.mendeley.com/datasets/dghdz45rfd/2\n",
    "        W = np.load(path_str + f\"{graph_str}/\"\n",
    "                    + \"mouse-control1-model.npz\")[\"J\"]\n",
    "\n",
    "    elif graph_str in [\"fully_connected_layer_cnn_00100\",\n",
    "                       \"fully_connected_layer_cnn_00200\",\n",
    "                       \"fully_connected_layer_cnn_00300\",\n",
    "                       \"fully_connected_layer_cnn_00400\",\n",
    "                       \"fully_connected_layer_cnn_00500\",\n",
    "                       \"fully_connected_layer_cnn_00600\",\n",
    "                       \"fully_connected_layer_cnn_00700\",\n",
    "                       \"fully_connected_layer_cnn_00800\",\n",
    "                       \"fully_connected_layer_cnn_00900\",\n",
    "                       \"fully_connected_layer_cnn_01000\"]:\n",
    "        # Data from https://github.com/gabrieleilertsen/nws\n",
    "\n",
    "        # theta is the notation of the paper : \"Classifying the classifier:\n",
    "        #  Dissecting the weight space of neural networks\" of\n",
    "        # G. Eilertsen et al.\n",
    "        theta = np.fromfile(path_str +\n",
    "                            f\"cnn/cnn_nws_main_{graph_str[-5:]}_020.bin\",\n",
    "                            'double')\n",
    "        meta = pd.read_csv(path_str+f\"cnn/meta_{graph_str[-5:]}.csv\")\n",
    "        # About the data\n",
    "        # with pd.option_context('display.max_rows', None,\n",
    "        #                        'display.max_columns', None):\n",
    "        #     print(meta)\n",
    "        fsize = meta[\"filter_size\"][0]\n",
    "        ldepth = [meta[\"depth_conv\"][0], meta[\"depth_fc\"][0]]\n",
    "        lwidth = [meta[\"width_conv\"][0], meta[\"width_fc\"][0]]\n",
    "\n",
    "        (conv, fc) = unpack(theta, fsize, ldepth, lwidth)\n",
    "        # From Gabriel Eilertsen :\n",
    "        # Here, conv and fc are lists with the separate layer weights for\n",
    "        # convolutional and fully connected layers, respectively. fc holds\n",
    "        # layers through the first index, i.e. fc[0,:] are the weights for\n",
    "        # the first fully connected layer, where fc[0,0] is the weight matrix,\n",
    "        #  fc[0,1] is the bias vector, and fc[0,2:] are weights for batch\n",
    "        # normalization.\n",
    "\n",
    "        weight_matrix_list = fc[:, 0]\n",
    "\n",
    "        # We now regroup the weights between each layer in one large square\n",
    "        # matrix characterizing the network structure of the\n",
    "        # fully-connected layers\n",
    "\n",
    "        # 1- getting block diagonal matrix\n",
    "        W = scipy.linalg.block_diag(*weight_matrix_list)\n",
    "        nb_neurons_in_first, nb_neurons_in_last = \\\n",
    "            weight_matrix_list[0].shape[0], weight_matrix_list[-1].shape[-1]\n",
    "\n",
    "        # 2- adding first columns of zeros\n",
    "        W = np.concatenate([np.zeros((W.shape[0], nb_neurons_in_first)), W],\n",
    "                           axis=1)\n",
    "\n",
    "        # 3- adding last row of zeros\n",
    "        W = np.concatenate([W, np.zeros((nb_neurons_in_last, W.shape[-1]))],\n",
    "                           axis=0)\n",
    "        # ^ This is a multipartite directed network\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"This graph_str learned is not an option. \"       \n",
    "                         \"See the documentation of \"\n",
    "                         \"get_learned_weight_matrix\")\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def get_economic_weight_matrix(graph_str):\n",
    "    path_str = f\"graph_data/economic/\"\n",
    "    if graph_str == \"AT_2008\":\n",
    "        \"\"\"Wachs, J., Fazekas, M. & Kertész, J. Corruption risk in\n",
    "         contracting markets: a network science perspective.                                            \n",
    "         Int J Data Sci Anal (2020). 10.1007/s41060-019-00204-1\"\"\"\n",
    "        # Directed, Weighted, Bipartite, Temporal\n",
    "        G = nx.read_gml(path_str + f'country_year_networks/{graph_str}.gml')\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"CY_2015\":\n",
    "        \"\"\"Wachs, J., Fazekas, M. & Kertész, J. Corruption risk in\n",
    "         contracting markets: a network science perspective. \n",
    "         Int J Data Sci Anal (2020). 10.1007/s41060-019-00204-1\"\"\"\n",
    "        # Directed, Weighted, Bipartite, Temporal\n",
    "        G = nx.read_gml(path_str + f'country_year_networks/{graph_str}.gml')\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"EE_2010\":\n",
    "        \"\"\"Wachs, J., Fazekas, M. & Kertész, J. Corruption risk in\n",
    "         contracting markets: a network science perspective. \n",
    "         Int J Data Sci Anal (2020). 10.1007/s41060-019-00204-1\"\"\"\n",
    "        # Directed, Weighted, Bipartite\n",
    "        G = nx.read_gml(path_str + f'country_year_networks/{graph_str}.gml')\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"PT_2009\":\n",
    "        \"\"\"Wachs, J., Fazekas, M. & Kertész, J. Corruption risk in\n",
    "         contracting markets: a network science perspective. \n",
    "         Int J Data Sci Anal (2020). 10.1007/s41060-019-00204-1\"\"\"\n",
    "        # Directed, Weighted, Bipartite\n",
    "        G = nx.read_gml(path_str + f'country_year_networks/{graph_str}.gml')\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"SI_2016\":\n",
    "        \"\"\"Wachs, J., Fazekas, M. & Kertész, J. Corruption risk in            \n",
    "         contracting markets: a network science perspective.                  \n",
    "         Int J Data Sci Anal (2020). 10.1007/s41060-019-00204-1\"\"\"\n",
    "        # Directed, Weighted, Bipartite\n",
    "        G = nx.read_gml(path_str + f'country_year_networks/{graph_str}.gml')\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"financial_institution07-Apr-1999\":\n",
    "        \"\"\" https://doi.org/10.1371/journal.pone.0198807 \"\"\"\n",
    "        # Undirected, Weighted\n",
    "        G = nx.read_weighted_edgelist(\n",
    "            path_str + f\"investor_nokia/{graph_str}.txt\", delimiter=',',\n",
    "            create_using=nx.Graph)\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"households_04-Sep-1998\":\n",
    "        \"\"\" https://doi.org/10.1371/journal.pone.0198807 \"\"\"\n",
    "        # Undirected, Weighted\n",
    "        G = nx.read_weighted_edgelist(\n",
    "            path_str + f\"investor_nokia/{graph_str}.txt\", delimiter=',',\n",
    "            create_using=nx.Graph)\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"households_09-Jan-2002\":\n",
    "        \"\"\" https://doi.org/10.1371/journal.pone.0198807 \"\"\"\n",
    "        # Undirected, Weighted\n",
    "        G = nx.read_weighted_edgelist(\n",
    "            path_str + f\"investor_nokia/{graph_str}.txt\", delimiter=',',\n",
    "            create_using=nx.Graph)\n",
    "        W = nx.to_numpy_array(G)\n",
    "\n",
    "    elif graph_str == \"non_financial_institution04-Jan-2001\":\n",
    "        \"\"\" https://doi.org/10.1371/journal.pone.0198807 \"\"\"\n",
    "        # Undirected, Weighted\n",
    "        G = nx.read_weighted_edgelist(\n",
    "            path_str + f\"investor_nokia/{graph_str}.txt\", delimiter=',',\n",
    "            create_using=nx.Graph)\n",
    "        W = nx.to_numpy_array(G)\n",
    "    else:\n",
    "        raise ValueError(\"This graph_str economic is not an option. \"       \n",
    "                         \"See the documentation of \"\n",
    "                         \"get_economic_weight_matrix\")\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06440bc",
   "metadata": {},
   "source": [
    "##### Code reproduisant ce que le fichier `extract_graph_properties.py` fait pour les graphes venant de `netzschleuder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5302e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_graph_properties(W, network_name, network_tag, network_url):\n",
    "\n",
    "    number_of_vertices = W.shape[0]\n",
    "\n",
    "    direction = 'directed'\n",
    "    if np.allclose(W, W.T):\n",
    "        direction = 'undirected'\n",
    "\n",
    "    selfloops = 'noselfloops'\n",
    "    if any(W.diagonal()):\n",
    "        selfloops = 'selfloops'\n",
    "\n",
    "    multiedges = 'nomultiedges'\n",
    "    weights = 'unweighted'\n",
    "    if np.array_equal(W, W.astype(int)):\n",
    "        if not np.array_equal(W, W.astype(bool)):\n",
    "            multiedges = 'multiedges'\n",
    "    else:\n",
    "        weights = 'weighted'\n",
    "\n",
    "    partite = 'N/A'\n",
    "\n",
    "    number_of_edges = np.count_nonzero(W)\n",
    "    if multiedges == 'multiedges':\n",
    "        number_of_edges = np.sum(np.absolute(W))\n",
    "\n",
    "    density = 2 * number_of_edges / (number_of_vertices * (number_of_vertices - 1))\n",
    "\n",
    "    nb_non_zero = np.count_nonzero(W)\n",
    "    nb_non_zero_diag = np.count_nonzero(W.diagonal())\n",
    "    if direction == 'undirected':\n",
    "        if selfloops == 'noselfloops':\n",
    "            bindensity = 2 * (nb_non_zero / 2) / (number_of_vertices * (number_of_vertices - 1))\n",
    "        else:\n",
    "            bindensity = 2 * ((nb_non_zero + nb_non_zero_diag) / 2) / (number_of_vertices * (number_of_vertices + 1))\n",
    "    if direction == 'directed':\n",
    "        if selfloops == 'noselfloops':\n",
    "            bindensity = nb_non_zero / (number_of_vertices * number_of_vertices)\n",
    "        else:\n",
    "            bindensity = nb_non_zero / (number_of_vertices * (number_of_vertices - 1))\n",
    "    \n",
    "    if direction == 'directed':\n",
    "        density /= 2\n",
    "        \n",
    "    average_degree = density * (number_of_vertices - 1)\n",
    "\n",
    "    return [network_name, direction, weights, partite, selfloops, multiedges, number_of_vertices, number_of_edges, density, bindensity, average_degree, network_tag, 'N/A', network_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ebd8e3",
   "metadata": {},
   "source": [
    "##### Les nouveaux graphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b0e44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# network_name = 'celegans'\n",
    "# network_tag = 'Biological,Connectome'\n",
    "\n",
    "# W = get_connectome_weight_matrix(network_name)\n",
    "# graphPropList.append(get_graph_properties(W, network_name, network_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929bfe5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'celegans_signed'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'https://doi.org/10.1016/j.neuron.2021.06.007'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bbb0b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'drosophila'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'https://doi.org/10.7554/eLife.57443'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23986a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'cintestinalis'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'https://doi.org/10.7554/eLife.16962'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cecf0eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'mouse_meso'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'http://dx.doi.org/%2010.1038/nature13186'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e90ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'pdumerilii_neuronal'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'https://doi.org/10.1101/2020.08.21.260984'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13790e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'pdumerilii_desmosomal'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'https://doi.org/10.7554/eLife.71231'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ea693e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'mouse_voxel'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'http://dx.doi.org/%2010.1126/SCIADV.ABB7187'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ba658a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'zebrafish_meso'\n",
    "network_tag = 'Biological,Connectome'\n",
    "network_url = 'http://dx.doi.org/10.1016/j.neuron.2019.04.034'\n",
    "\n",
    "W = get_connectome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b0300ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'gut'\n",
    "network_tag = 'Biological,Microbiome'\n",
    "network_url = 'https://doi.org/10.1038/s41597-020-0516-5'\n",
    "\n",
    "W = get_microbiome_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d568d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# network_name = 'little_rock'\n",
    "# network_tag = 'Biological,Foodweb'\n",
    "# \n",
    "# W = get_foodweb_weight_matrix(network_name)\n",
    "# graphPropList.append(get_graph_properties(W, network_name, network_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbb6de21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# network_name = 'caribbean'\n",
    "# network_tag = 'Biological,Foodweb'\n",
    "# \n",
    "# W = get_foodweb_weight_matrix(network_name)\n",
    "# graphPropList.append(get_graph_properties(W, network_name, network_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b2f3f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'high_school_proximity'\n",
    "network_tag = 'Social'\n",
    "network_url = 'www.sociopatterns.org/wp-content/uploads/2015/07/High-School_data_2013.csv.gz'\n",
    "\n",
    "W = get_epidemiological_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d7b5a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'zebrafish_rnn'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'http://dx.doi.org/%2010.1016/j.neuron.2021.06.007'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26899339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'mouse_rnn'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'http://dx.doi.org/%2010.1016/j.neuron.2021.06.007'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5e8d0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'mouse_control_rnn'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'http://dx.doi.org/%2010.1016/j.neuron.2021.06.007'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0514134f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00100'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7481798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00200'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc0f0c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00300'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2484f7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00400'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bc4e37e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00500'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e02247c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00600'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f330ead3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00700'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e69481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00800'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ee0f005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_00900'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17f108d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'fully_connected_layer_cnn_01000'\n",
    "network_tag = 'Learned'\n",
    "network_url = 'https://github.com/gabrieleilertsen/nws'\n",
    "\n",
    "W = get_learned_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c3b5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'AT_2008'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.1007/s41060-019-00204-1'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4d67b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'CY_2015'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.1007/s41060-019-00204-1'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7bfbc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'EE_2010'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.1007/s41060-019-00204-1'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dfb89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'PT_2009'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.1007/s41060-019-00204-1'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "975efd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'SI_2016'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.1007/s41060-019-00204-1'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f86c2a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'financial_institution07-Apr-1999'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.5061/dryad.5b8n621'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6866f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'households_04-Sep-1998'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.5061/dryad.5b8n621'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2607ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'households_09-Jan-2002'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.5061/dryad.5b8n621'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b820837",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'non_financial_institution04-Jan-2001'\n",
    "network_tag = 'Economic'\n",
    "network_url = 'https://doi.org/10.5061/dryad.5b8n621'\n",
    "\n",
    "W = get_economic_weight_matrix(network_name)\n",
    "graphPropList.append(get_graph_properties(W, network_name, network_tag, network_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a6d8f",
   "metadata": {},
   "source": [
    "##### Sauvegarde toutes les propriétés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a069b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPropFilename = 'graph_data/graph_properties_augmented.txt'\n",
    "graphPropDF = pd.DataFrame(graphPropList, columns=header)\n",
    "graphPropDF.sort_values('name', inplace=True)\n",
    "graphPropDF.reset_index(drop=True, inplace=True)\n",
    "graphPropDF.to_fwf(graphPropFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9d807a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drosophila                                            directed      unweighted               N/A  noselfloops    multiedges         21733       1.41492e+07    0.0299581         651.049                                        Biological,Connectome                   N/A\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv 3.9.0",
   "language": "python",
   "name": "3.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
